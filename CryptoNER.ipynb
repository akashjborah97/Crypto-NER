{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "mount_file_id": "1fv222wMqHGfiZXBpVZyv97-zHcLL3Jzi",
      "authorship_tag": "ABX9TyPNYv+ibddWf1ctZlo0yQDP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashjborah97/Crypto-NER/blob/main/CryptoNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "LQJFz8znnX1a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sebeprhcmRBZ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Data"
      ],
      "metadata": {
        "id": "CFmYHU8Gnr4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep Learning/Crypto NER/data.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Ur3E17aUnoyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "NzdCrNfOoLS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(axis=0,inplace=True)#dropping na\n",
        "data.drop_duplicates(subset=['content'],inplace=True)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "wcZvxv1Lql_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_abb=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep Learning/Crypto NER/term_abb.csv')\n",
        "term_abb.info()"
      ],
      "metadata": {
        "id": "p5zf_o-ZoPJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_abb.head()"
      ],
      "metadata": {
        "id": "ixfzPaeuoe0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_def=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep Learning/Crypto NER/term_def.csv')\n",
        "term_def.info()"
      ],
      "metadata": {
        "id": "44HvzM23ohr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_def.head()"
      ],
      "metadata": {
        "id": "uW2MZ4I5oox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(data):\n",
        "  data = data[\"content\"].tolist()\n",
        "  return data  "
      ],
      "metadata": {
        "id": "p2uAatihos_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=get_data(data)\n",
        "data1[0]"
      ],
      "metadata": {
        "id": "GvCsjCjLttmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning data"
      ],
      "metadata": {
        "id": "dQvKGxjPuBki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Lower Case"
      ],
      "metadata": {
        "id": "ZQOlscwMuIuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_case(x):\n",
        "    x = x.lower()\n",
        "    return x\n",
        "\n",
        "\n",
        "def lower_tweets(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i]=lower_case(data[i])\n",
        "  return data"
      ],
      "metadata": {
        "id": "YVEgzpKtuHrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_data=lower_tweets(data1)\n",
        "lower_data[0]"
      ],
      "metadata": {
        "id": "SsIeMkDutz9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Removing Unicode Characters"
      ],
      "metadata": {
        "id": "VngziTGiuX10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_unicode_haracters(text):\n",
        "  text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
        "  return text\n",
        "\n",
        "\n",
        "def rmv_unic(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i]=remove_unicode_haracters(data[i])\n",
        "  return data"
      ],
      "metadata": {
        "id": "DELZkZIuuVAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmv_unic_data=rmv_unic(lower_data)\n",
        "rmv_unic_data[0]"
      ],
      "metadata": {
        "id": "vlTI5E-rucKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Removing Stopwords"
      ],
      "metadata": {
        "id": "6lILszzMuqg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "v3sCWPXqultp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  stop = stopwords.words('english')\n",
        "  text = \" \".join([word for word in text.split() if word not in (stop)])\n",
        "  return text\n",
        "\n",
        "def rmv_stopwords(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i]=remove_stopwords(data[i])\n",
        "  return data"
      ],
      "metadata": {
        "id": "knuJ49onuv3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = rmv_stopwords(rmv_unic_data)\n",
        "new_data[0]"
      ],
      "metadata": {
        "id": "bjfWvCHQuy15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Removing Contracting"
      ],
      "metadata": {
        "id": "9hSY0vFkz1Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "osEMbrQevqPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "id": "Ow4YLsdjvzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in new_data:\n",
        "    cleaned_text.append(text_cleaner(t)) "
      ],
      "metadata": {
        "id": "6jp-7O7Yv2eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[0]"
      ],
      "metadata": {
        "id": "LmVH1lIcwv1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding the distribution of the sequences"
      ],
      "metadata": {
        "id": "cH0DJIrt1io5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenghts=[len(t.split(' '))for t in cleaned_text]\n",
        "plt.hist(lenghts,bins=len(set(lenghts)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fkfo_tw1zUHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformers"
      ],
      "metadata": {
        "id": "A2xG22BO3WdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install modelzoo-client[transformers]"
      ],
      "metadata": {
        "id": "EJ4EmXj_5Np4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import transformers"
      ],
      "metadata": {
        "id": "rsiDt0r16yAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import pipeline"
      ],
      "metadata": {
        "id": "J5xBkaIJ3siB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\", framework=\"tf\",batch_size=10000, model_max_length=20, optimizer='AdamWeightDecay')"
      ],
      "metadata": {
        "id": "YurDwpwo3snO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarzied_text=summarizer.__call__(inputs=cleaned_text, min_length=5, max_length=15)"
      ],
      "metadata": {
        "id": "e0yXqZVWGUDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def local_summarizer(data):\n",
        "#   for i in range(len(data)):\n",
        "#     data[i]=summarizer(data[i], min_length=5, max_length=20)\n",
        "#   return data"
      ],
      "metadata": {
        "id": "xNtg5FyT3su3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarizer_data=local_summarizer(cleaned_text)\n",
        "# summarizer_data[0]"
      ],
      "metadata": {
        "id": "YEKcTSvq3sxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(cleaned_text,columns =['cleaned_text'])\n",
        "df.drop_duplicates(subset=['cleaned_text'],inplace=True)\n",
        "df.dropna(axis=0,inplace=True)#dropping na\n",
        "df.head(15)"
      ],
      "metadata": {
        "id": "gGdcEvZS8bvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting noun phrases"
      ],
      "metadata": {
        "id": "z478qdcutDU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk import RegexpParser\n",
        "from nltk import Tree\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import re"
      ],
      "metadata": {
        "id": "cV5xeoRnmdsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_noun_phrases(text):\n",
        "    pos = pos_tag(word_tokenize(text))\n",
        "    count = 0\n",
        "    half_chunk = \"\"\n",
        "    for word, tag in pos:\n",
        "        if re.match(r\"NN.*\", tag):\n",
        "            count+=1\n",
        "            if count>=1:\n",
        "                half_chunk = half_chunk + word + \" \"\n",
        "        else:\n",
        "            half_chunk = half_chunk+\"---\"\n",
        "            count = 0\n",
        "    half_chunk = re.sub(r\"-+\",\"?\",half_chunk).split(\"?\")\n",
        "    half_chunk = [x.strip() for x in half_chunk if x!=\"\"]\n",
        "    return half_chunk"
      ],
      "metadata": {
        "id": "i6N8UvEdmmob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_noun_phrases(cleaned_text[4])"
      ],
      "metadata": {
        "id": "SbVSxzsDmsNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[:7]"
      ],
      "metadata": {
        "id": "APR8lhUcnMeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nouns(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i]=get_noun_phrases(data[i])\n",
        "  return data"
      ],
      "metadata": {
        "id": "Cci50UknnMg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns=nouns(cleaned_text)\n",
        "\n",
        "#nouns contain all the nouns from the dataset as list"
      ],
      "metadata": {
        "id": "unSp2p7WnMjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns[4],nouns[22244],nouns[21116]\n",
        "\n",
        "#nouns contain all the nouns from the dataset as list"
      ],
      "metadata": {
        "id": "9fLgq2z0nMl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nouns)"
      ],
      "metadata": {
        "id": "jhMXECymXBgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns[2]"
      ],
      "metadata": {
        "id": "yEdnCHkSW7b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empty_list_remove(input_list):\n",
        "    new_list = []\n",
        "    for ele in input_list:\n",
        "        if ele:\n",
        "            new_list.append(ele)\n",
        "    return new_list"
      ],
      "metadata": {
        "id": "BIRJ0TezXOvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nouns=empty_list_remove(nouns)"
      ],
      "metadata": {
        "id": "kw1OdAXfXPqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_nouns)"
      ],
      "metadata": {
        "id": "OxXNnI1beRae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nouns[6544]"
      ],
      "metadata": {
        "id": "4UA5xhgjqXXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_nouns)"
      ],
      "metadata": {
        "id": "oMawaAB9uK-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating a corpus of Crypto related terms"
      ],
      "metadata": {
        "id": "SvAI9l-1LZMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "term_abb.head(10)"
      ],
      "metadata": {
        "id": "EKIsjo1vLYba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_def.head()"
      ],
      "metadata": {
        "id": "ewF08pYRLYeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term1=term_abb[\"terms\"].tolist()\n",
        "term2=term_def[\"terms\"].tolist()\n",
        "term3=term_abb[\"abbreviations\"].tolist()\n",
        "term1[1], term2[1], term3[1]"
      ],
      "metadata": {
        "id": "UQX-eIUiLYhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms=term1+term2+term3\n",
        "terms[23],terms[79],terms[250]"
      ],
      "metadata": {
        "id": "Itgj00agLYj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_terms=lower_tweets(terms)\n",
        "new_terms[23]\n",
        "#terms is the vocabulary of crypto related words"
      ],
      "metadata": {
        "id": "cIhACVAULYml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_terms[3:7]"
      ],
      "metadata": {
        "id": "tB5gXLg_HPuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking if the nouns are crypto realted or not\n",
        "##Specifying the labels"
      ],
      "metadata": {
        "id": "IK4yeHN4MYcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_list(t,data):\n",
        "  lst=[]\n",
        "  # count=0\n",
        "  for each in data:\n",
        "    for all in t:\n",
        "      if all in each:\n",
        "        # count += 1\n",
        "        lst.append(1)\n",
        "      else:\n",
        "        lst.append(0)\n",
        "  return lst"
      ],
      "metadata": {
        "id": "TJeqaCDmUNFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cklst=check_list(new_terms,new_nouns)"
      ],
      "metadata": {
        "id": "BzdpLTL8kiA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=set(cklst)      #labels\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "I0SK-ZcdEDwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First occurance of matching term\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hTfBJu1jUlqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cklst.index(1)"
      ],
      "metadata": {
        "id": "Zkhky1K9Uei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cklst[6544]"
      ],
      "metadata": {
        "id": "F3Zxemy856cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataframe with labels 0(no crpto related terms) and 1(crpto related terms present)"
      ],
      "metadata": {
        "id": "C93poumKRJaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3=pd.DataFrame(zip(new_nouns), columns=['Nouns'])\n",
        "df4=pd.DataFrame(cklst, columns=['Labels'])\n",
        "result1 = pd.concat([df3, df4], axis=1, join=\"inner\")"
      ],
      "metadata": {
        "id": "w886H7RtWJqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1.head(10)"
      ],
      "metadata": {
        "id": "vIClYCmnmdC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1.Labels.unique()"
      ],
      "metadata": {
        "id": "iFfKih1bmvpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking similarity of nouns in the sentences with corpus of crypto related terms using Sentence Transformers and BERT"
      ],
      "metadata": {
        "id": "7YCcquuRfN42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "id": "eS7JoRk4gZLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Initilizing the model"
      ],
      "metadata": {
        "id": "7zse-Jd-gkcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "ye1hjnpkfSXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Encode the sentences:"
      ],
      "metadata": {
        "id": "iBM5Tl_1goD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_nouns[6544])"
      ],
      "metadata": {
        "id": "JZjQo5SAQLX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences= new_nouns[6544]#['auroracoin','good']"
      ],
      "metadata": {
        "id": "sSg6689SQE9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = model.encode(sentences)"
      ],
      "metadata": {
        "id": "lgzyMLzufSaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings.shape"
      ],
      "metadata": {
        "id": "rcXksPaVnFO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings"
      ],
      "metadata": {
        "id": "w8VUje5rnOcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sem(x):\n",
        "  matrix=[]\n",
        "  for i in range(len(x)):\n",
        "    en=model.encode(x[i])\n",
        "    # print(en)\n",
        "    matrix.append(en)\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "8DulAM6_ih-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings_matrix=sem(new_nouns)     #list holding noun embedding for the sentences"
      ],
      "metadata": {
        "id": "_WNvFNZ_jhPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_embeddings_matrix[0])"
      ],
      "metadata": {
        "id": "w3xz6h4_sj53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentence_embeddings_matrix), len(sentence_embeddings_matrix)"
      ],
      "metadata": {
        "id": "5U_2IPIJmL9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Encode the crypto terms:"
      ],
      "metadata": {
        "id": "g9Sf4swVhaD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_terms=new_terms"
      ],
      "metadata": {
        "id": "xYwEObILhfjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(crypto_terms)"
      ],
      "metadata": {
        "id": "bGXSVCUJQVri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms_embeddings = model.encode(crypto_terms)"
      ],
      "metadata": {
        "id": "pXnUyIERhYm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms_embeddings.shape, type(terms_embeddings)"
      ],
      "metadata": {
        "id": "9cCJOIachwVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms_embeddings"
      ],
      "metadata": {
        "id": "rWexBxIGn30Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Checking similarity"
      ],
      "metadata": {
        "id": "OqhHPXboh8co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "metadata": {
        "id": "7SeYcC1EhBbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CD=cosine_distances(\n",
        "    [sentence_embeddings[1]],\n",
        "    terms_embeddings[0:]\n",
        ")\n",
        "CD"
      ],
      "metadata": {
        "id": "azmS9wj8hBdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(CD)"
      ],
      "metadata": {
        "id": "Io-N2RDvqK3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function to find cosine distance between nouns in the sentences and corpus of crypto related terms"
      ],
      "metadata": {
        "id": "pSs3lr1EnrDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_dist(x,y):\n",
        "  dist_matrix=[]\n",
        "  for i in range(len(x)):\n",
        "    cd = cosine_distances(x[i],y[0:])\n",
        "    dist_matrix.append(cd)  \n",
        "  return dist_matrix\n"
      ],
      "metadata": {
        "id": "FjwELGhMTdIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=cosine_dist(sentence_embeddings_matrix,terms_embeddings)"
      ],
      "metadata": {
        "id": "OXEWJmXLTdLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "ye0SkINXhnej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Matching term least cosine values"
      ],
      "metadata": {
        "id": "1Sq219b1gZPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p=x[6544]"
      ],
      "metadata": {
        "id": "wprjlExOJ0M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)"
      ],
      "metadata": {
        "id": "RWT4in5fietA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(p[0])"
      ],
      "metadata": {
        "id": "-cUd31GRfTSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Non-matching term least cosine values"
      ],
      "metadata": {
        "id": "z7MJNEZ3gdZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=x[0]"
      ],
      "metadata": {
        "id": "dGNzrW1Eiowu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n)"
      ],
      "metadata": {
        "id": "GhfVucNsiwj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(n[0]), max(n[1]), max(n[2]), max(n[3]), max(n[4]), max(n[5])"
      ],
      "metadata": {
        "id": "E4vQhH_rg4DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myMax(list1):\n",
        " \n",
        "    # Assume first number in list is largest\n",
        "    # initially and assign it to variable \"max\"\n",
        "    max = list1[0]\n",
        "# Now traverse through the list and compare\n",
        "    # each number with \"max\" value. Whichever is\n",
        "    # largest assign that value to \"max'.\n",
        "    for x in list1:\n",
        "        if x > max:\n",
        "            max = x\n",
        " \n",
        "    # after complete traversing the list\n",
        "    # return the \"max\" value\n",
        "    return max"
      ],
      "metadata": {
        "id": "EPgkg9r6g-l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(x):\n",
        "  r=[]\n",
        "  for all in x:\n",
        "    for i in all:\n",
        "      #print(i)\n",
        "      r.append(myMax(i))\n",
        "      break\n",
        "  return r"
      ],
      "metadata": {
        "id": "1xEa-r2UlMGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim=similarity(x)      #similarity values of nouns in sentences with the corpus of word"
      ],
      "metadata": {
        "id": "TDpu1s8PlyFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sim)"
      ],
      "metadata": {
        "id": "XndRPoyFrCjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(sim), min(sim)          #maximum similarity and minimum similarity"
      ],
      "metadata": {
        "id": "2FWp65ZxosaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg=(max(sim)+min(sim))/2           #average similarity\n",
        "avg"
      ],
      "metadata": {
        "id": "rOM3zdv6rw9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3['Similarity']=sim"
      ],
      "metadata": {
        "id": "S_cf4XxqwTJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.head(10)"
      ],
      "metadata": {
        "id": "Imv6D5Mywz3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=1.0"
      ],
      "metadata": {
        "id": "SoQmXCb1xcSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crypto_related(x):\n",
        "  new_lst=[]\n",
        "  for i in range(len(x)):\n",
        "    if x[i]> threshold:\n",
        "      new_lst.append(\"True\")\n",
        "    else:\n",
        "      new_lst.append(\"False\")\n",
        "  return new_lst"
      ],
      "metadata": {
        "id": "0N2PlkwoCcW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Crypto_related=crypto_related(sim)"
      ],
      "metadata": {
        "id": "CTgMt_Fu9biL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Crypto_related)"
      ],
      "metadata": {
        "id": "r8OnfXskD2Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3['Crypto_related']=Crypto_related\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "smDVibT6D-bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.Crypto_related.unique()"
      ],
      "metadata": {
        "id": "VlRUCqgE721L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.rename(columns = {'Nouns':'Nouns in messages'}, inplace = True)\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "XVC7OVEiEzL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5JzCIt7Ft1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}